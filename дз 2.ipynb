{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Домашнее задание 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В первую очередь запускаю проверку по PEP-8:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext pycodestyle_magic\n",
    "%pycodestyle_on"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Потом в отдельную ячейку выношу все импорты и инстоллы, чтобы они не мешали дальше:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ! pip3 install pycodestyle flake8 pycodestyle_magic\n",
    "# ! pip install pymystem3\n",
    "# ! pip install pymorphy2\n",
    "# ! pip install nltk\n",
    "# nltk.download('punkt')\n",
    "import json\n",
    "import nltk\n",
    "import re\n",
    "from collections import Counter\n",
    "from pymystem3 import Mystem\n",
    "from pprint import pprint\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import bigrams\n",
    "from nltk.util import ngrams\n",
    "from pymorphy2 import MorphAnalyzer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Первое задание**\n",
    "\n",
    "* распарсить с помощью mystem\n",
    "* замерить время работы\n",
    "* сохранить результат в json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Время выполнения парсинга:\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pymystem3\\mystem.py\u001b[0m in \u001b[0;36manalyze\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m    248\u001b[0m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    249\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplitlines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 250\u001b[1;33m             \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_analyze_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    251\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    252\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pymystem3\\mystem.py\u001b[0m in \u001b[0;36m_analyze_impl\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m    311\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_procin\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_NL\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 313\u001b[1;33m             \u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_proc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommunicate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    314\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_proc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    315\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\subprocess.py\u001b[0m in \u001b[0;36mcommunicate\u001b[1;34m(self, input, timeout)\u001b[0m\n\u001b[0;32m    937\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    938\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 939\u001b[1;33m                 \u001b[0mstdout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstderr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_communicate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mendtime\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    940\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    941\u001b[0m                 \u001b[1;31m# https://bugs.python.org/issue25942\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\subprocess.py\u001b[0m in \u001b[0;36m_communicate\u001b[1;34m(self, input, endtime, orig_timeout)\u001b[0m\n\u001b[0;32m   1265\u001b[0m             \u001b[1;31m# calls communicate again.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1266\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstdout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1267\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstdout_thread\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_remaining_time\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mendtime\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1268\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstdout_thread\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_alive\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1269\u001b[0m                     \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutExpired\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morig_timeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\threading.py\u001b[0m in \u001b[0;36mjoin\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m   1030\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1031\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1032\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_wait_for_tstate_lock\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1033\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1034\u001b[0m             \u001b[1;31m# the behavior of a negative timeout isn't documented, but\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\threading.py\u001b[0m in \u001b[0;36m_wait_for_tstate_lock\u001b[1;34m(self, block, timeout)\u001b[0m\n\u001b[0;32m   1046\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlock\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# already determined that the C code is done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1047\u001b[0m             \u001b[1;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_stopped\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1048\u001b[1;33m         \u001b[1;32melif\u001b[0m \u001b[0mlock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1049\u001b[0m             \u001b[0mlock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1050\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3:1: E115 expected an indented block (comment)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Готово, данные анализа записаны в файл \"Mystem_analysis.json\"\n"
     ]
    }
   ],
   "source": [
    "m = Mystem()\n",
    "with open('По ту сторону поводка.txt', encoding='UTF-8') as f:  # большой текст\n",
    "# with open('Отрывок.txt', encoding='UTF-8') as f:  # один абзац\n",
    "    text = f.read()\n",
    "print('Время выполнения парсинга:')\n",
    "%time  analysis = m.analyze(text)\n",
    "with open('Mystem_analysis.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(analysis, f, ensure_ascii=False)\n",
    "print('\\n' + 'Готово, данные анализа записаны в файл \"Mystem_analysis.json\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Второе задание**\n",
    "\n",
    "Измерение времени работы пришлось заккоментировать, т.к. с ним почему-то не работают выводы в следующих ячейках.\n",
    "\n",
    "Сначала токенизиую текст через nltk. Под решёткой оставляю вариант с токенизацией всего подряд, но мне кажется, нет смысла дальше анализировать часть речи у знаков препинания. Для анализа беру только первое значение в случае, если их несколько. Извлекаю из тега лемму и часть речи. Записываю в файл json."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Готово, данные анализа записаны в файл \"Pymorphy_analysis.json\"\n"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "morph = MorphAnalyzer()\n",
    "# words = word_tokenize(text)  так остаётся пунктуация\n",
    "words = [w.lower() for w in word_tokenize(text) if w.isalpha()]  # а так нет\n",
    "analysis_2 = []\n",
    "pair = {}\n",
    "for word in words:\n",
    "    result = morph.parse(word)\n",
    "    first = result[0]\n",
    "    lemma = first.normal_form\n",
    "    pos = first.tag.POS\n",
    "    pair = dict([(lemma, pos)])\n",
    "    analysis_2.append(pair)\n",
    "with open('Pymorphy_analysis.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(analysis_2, f, ensure_ascii=False)\n",
    "print('\\n' + 'Готово, данные анализа записаны в файл \"Pymorphy_analysis.json\"')\n",
    "# print('\\n' + 'Время выполнения задач:')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Третье задание, часть 1**\n",
    "\n",
    "Не самый красивый код, но мне захотелось сделать красивый русскоязычный вывод, а не просто сокращенную части речи и число.\n",
    "\n",
    "NB: слова с пометой INFN здесь считаются за глаголы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Доля глаголов в тексте:  0.13157894736842105\n",
      "Доля прилагательных в тексте:  0.18421052631578946\n",
      "Доля существительных в тексте:  0.3684210526315789\n",
      "Доля наречий в тексте:  0.013157894736842105\n",
      "Доля местоимений в тексте:  0.06578947368421052\n",
      "Доля союзов в тексте:  0.09210526315789473\n",
      "Доля предлогов в тексте:  0.13157894736842105\n"
     ]
    }
   ],
   "source": [
    "words_nums = re.findall(r\"[\\w]+\", text)\n",
    "verb = []\n",
    "adj = []\n",
    "noun = []\n",
    "pron = []\n",
    "conj = []\n",
    "prep = []\n",
    "inf = []\n",
    "adv = []\n",
    "for i in analysis_2:\n",
    "    for key in i.keys():\n",
    "        if i[key] == 'VERB':\n",
    "            verb.append(i[key])\n",
    "        if i[key] == 'ADJF':\n",
    "            adj.append(i[key])\n",
    "        if i[key] == 'NOUN':\n",
    "            noun.append(i[key])\n",
    "        if i[key] == 'NPRO':\n",
    "            pron.append(i[key])\n",
    "        if i[key] == 'CONJ':\n",
    "            conj.append(i[key])\n",
    "        if i[key] == 'PREP':\n",
    "            prep.append(i[key])\n",
    "        if i[key] == 'INFN':\n",
    "            inf.append(i[key])\n",
    "        if i[key] == 'ADVB':\n",
    "            adv.append(i[key])\n",
    "print('Доля глаголов в тексте: ', (len(verb) + len(inf)) / len(words_nums))\n",
    "print('Доля прилагательных в тексте: ', len(adj) / len(words_nums))\n",
    "print('Доля существительных в тексте: ', len(noun) / len(words_nums))\n",
    "print('Доля наречий в тексте: ', len(adv) / len(words_nums))\n",
    "print('Доля местоимений в тексте: ', len(pron) / len(words_nums))\n",
    "print('Доля союзов в тексте: ', len(conj) / len(words_nums))\n",
    "print('Доля предлогов в тексте: ', len(prep) / len(words_nums))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Третье задание, часть 2**\n",
    "\n",
    "Раскидываю слова по спискам глаголов и наречий по результатам парсинга, затем каунтером нахожу самые частотные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Топ-20 глаголов: \n",
      "\n",
      "'учит', 1\n",
      "'знакомит', 1\n",
      "'вносит', 1\n",
      "'рассказывает', 1\n",
      "'дает', 1\n",
      "'живет', 1\n",
      "'работает', 1\n",
      "'стремится', 1\n",
      "\n",
      " Топ-20 наречий: \n",
      "\n",
      "'убедительно', 1\n"
     ]
    }
   ],
   "source": [
    "verbs_2 = []\n",
    "advs_2 = []\n",
    "for word in words:\n",
    "    result = morph.parse(word)\n",
    "    first = result[0]\n",
    "    if first.tag.POS == 'VERB':\n",
    "        verbs_2.append(word)\n",
    "    if first.tag.POS == 'ADVB':\n",
    "        advs_2.append(word)\n",
    "top_verbs = Counter(verbs_2).most_common(20)\n",
    "top_advs = Counter(advs_2).most_common(20)\n",
    "print('Топ-20 глаголов:', '\\n')\n",
    "for v in top_verbs:\n",
    "    print(str(v).strip(')('))\n",
    "print('\\n', 'Топ-20 наречий:', '\\n')\n",
    "for a in top_advs:\n",
    "    print(str(a).strip(')('))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Четвертое задание**\n",
    "\n",
    "Сначала делаю список всех лемм, вытащенных из Pymorphy.\n",
    "\n",
    "У nltk есть отдельный способ получить биграммы, и отдельный способ для любых n-грамм. Я использовала оба, чтобы получить опыт с ними, хотя у ngrams можно задать любое число.\n",
    "\n",
    "Почему получаются именно такие n-граммы? Допишу ответ, если ноутбук потянет обработку всей книги, а не отрывка."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Топ-25 биграмм: \n",
      "\n",
      "(('по', 'тот'), 1)\n",
      "(('тот', 'сторона'), 1)\n",
      "(('сторона', 'поводок'), 1)\n",
      "(('поводок', 'убедительно'), 1)\n",
      "(('убедительно', 'учить'), 1)\n",
      "(('учить', 'наблюдать'), 1)\n",
      "(('наблюдать', 'сам'), 1)\n",
      "(('сам', 'себя'), 1)\n",
      "(('себя', 'и'), 1)\n",
      "(('и', 'наш'), 1)\n",
      "(('наш', 'собака'), 1)\n",
      "(('собака', 'пользоваться'), 1)\n",
      "(('пользоваться', 'язык'), 1)\n",
      "(('язык', 'тело'), 1)\n",
      "(('тело', 'и'), 1)\n",
      "(('и', 'голос'), 1)\n",
      "(('голос', 'она'), 1)\n",
      "(('она', 'знакомить'), 1)\n",
      "(('знакомить', 'с'), 1)\n",
      "(('с', 'социальный'), 1)\n",
      "(('социальный', 'сущность'), 1)\n",
      "(('сущность', 'собака'), 1)\n",
      "(('собака', 'вносить'), 1)\n",
      "(('вносить', 'корректив'), 1)\n",
      "(('корректив', 'в'), 1)\n",
      "\n",
      " Топ-25 триграмм: \n",
      "\n",
      "(('по', 'тот', 'сторона'), 1)\n",
      "(('тот', 'сторона', 'поводок'), 1)\n",
      "(('сторона', 'поводок', 'убедительно'), 1)\n",
      "(('поводок', 'убедительно', 'учить'), 1)\n",
      "(('убедительно', 'учить', 'наблюдать'), 1)\n",
      "(('учить', 'наблюдать', 'сам'), 1)\n",
      "(('наблюдать', 'сам', 'себя'), 1)\n",
      "(('сам', 'себя', 'и'), 1)\n",
      "(('себя', 'и', 'наш'), 1)\n",
      "(('и', 'наш', 'собака'), 1)\n",
      "(('наш', 'собака', 'пользоваться'), 1)\n",
      "(('собака', 'пользоваться', 'язык'), 1)\n",
      "(('пользоваться', 'язык', 'тело'), 1)\n",
      "(('язык', 'тело', 'и'), 1)\n",
      "(('тело', 'и', 'голос'), 1)\n",
      "(('и', 'голос', 'она'), 1)\n",
      "(('голос', 'она', 'знакомить'), 1)\n",
      "(('она', 'знакомить', 'с'), 1)\n",
      "(('знакомить', 'с', 'социальный'), 1)\n",
      "(('с', 'социальный', 'сущность'), 1)\n",
      "(('социальный', 'сущность', 'собака'), 1)\n",
      "(('сущность', 'собака', 'вносить'), 1)\n",
      "(('собака', 'вносить', 'корректив'), 1)\n",
      "(('вносить', 'корректив', 'в'), 1)\n",
      "(('корректив', 'в', 'прежний'), 1)\n"
     ]
    }
   ],
   "source": [
    "lemmas = []\n",
    "for word in words:\n",
    "    result = morph.parse(word)\n",
    "    first = result[0]\n",
    "    lemma = first.normal_form\n",
    "    lemmas.append(lemma)\n",
    "bi = list(bigrams(lemmas))\n",
    "tri = ngrams(lemmas, 3)\n",
    "top_bi = Counter(bi).most_common(25)\n",
    "top_tri = Counter(tri).most_common(25)\n",
    "print('Топ-25 биграмм:', '\\n')\n",
    "for b in top_bi:\n",
    "    print(b)\n",
    "print('\\n', 'Топ-25 триграмм:', '\\n')\n",
    "for t in top_tri:\n",
    "    print(t)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
